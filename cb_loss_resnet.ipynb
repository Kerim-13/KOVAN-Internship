{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cb_loss_resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wO4LEpCH-EVA"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9799c7bb53ba4c64a8fbd90be988cdff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c48dcb9bc9244f40bd1bb5c76611b7b2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fb917ed7ee5b44fba9ef3b6bf528cce6",
              "IPY_MODEL_e55e70b50aa34e659bda94931c5a34d2",
              "IPY_MODEL_2844ca90e9314d229d8c87194333ef60"
            ]
          }
        },
        "c48dcb9bc9244f40bd1bb5c76611b7b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb917ed7ee5b44fba9ef3b6bf528cce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6bf0354c88024b45a464b947f24e6356",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_895537a5f57945b2bc778d107d49ea28"
          }
        },
        "e55e70b50aa34e659bda94931c5a34d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d785269286b74737a9e9aef8c4b81518",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_920645b59c174b48a4fa6d8819fa5152"
          }
        },
        "2844ca90e9314d229d8c87194333ef60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fce111deeb6241a897780073ede28856",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 54458502.72it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f22352f713e4cc9b6cd0cb7aad741c4"
          }
        },
        "6bf0354c88024b45a464b947f24e6356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "895537a5f57945b2bc778d107d49ea28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d785269286b74737a9e9aef8c4b81518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "920645b59c174b48a4fa6d8819fa5152": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fce111deeb6241a897780073ede28856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f22352f713e4cc9b6cd0cb7aad741c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be7MPmlGK_qo"
      },
      "source": [
        "---\n",
        "\n",
        "#NOTICE\n",
        "\n",
        "This project is not actively maintained and is currently being rewritten as a library. Please refer to [imbalance-baselines](https://github.com/metu-balance/imbalance-baselines) GitHub page for the latest revision.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO4LEpCH-EVA"
      },
      "source": [
        "# Training ResNets Using Class-Balanced Loss\n",
        "\n",
        "Long-tailed CIFAR-10 dataset class was adapted from:\n",
        "\n",
        "https://github.com/kaidic/LDAM-DRW/blob/master/imbalance_cifar.py\n",
        "\n",
        "iNaturalist dataset class was adapted from:\n",
        "\n",
        "https://github.com/macaodha/inat_comp_2018/blob/master/inat2018_loader.py\n",
        "\n",
        "https://pytorch.org/vision/master/_modules/torchvision/datasets/inaturalist.html\n",
        "\n",
        "The class-balanced focal loss function was adapted from:\n",
        "\n",
        "https://github.com/richardaecn/class-balanced-loss/blob/master/src/cifar_main.py#L226-L266\n",
        "\n",
        "https://github.com/vandit15/Class-balanced-loss-pytorch/blob/master/class_balanced_loss.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoNz9RdS6kaK"
      },
      "source": [
        "# Initializations & Definitions\n",
        "Please make the desired initializations and **run the code blocks below before the first run**.\n",
        "\n",
        "Also, run the initialization block **whenever a change is made**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h9q1tPgYmJV"
      },
      "source": [
        "BATCH_SIZE = 128  #@param{type:\"integer\"}\n",
        "EPOCH_CNT =   200#@param{type:\"integer\"}\n",
        "MULTI_GPU = True  #@param{type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "DATASET = \"IMB_CIFAR10\"  #@param [\"CIFAR10\", \"IMB_CIFAR10\", \"INATURALIST_2017\", \"INATURALIST_2018\"]\n",
        "CIFAR_IMB_FACTOR = 50  #@param [10, 20, 50, 100, 200]\n",
        "INAT_32X32 = False  #@param{type:\"boolean\"}\n",
        "\n",
        "DSET_NAMES = {\n",
        "    \"CIFAR10\": \"CIFAR10\",\n",
        "    \"IMB_CIFAR10\": \"Long-Tailed CIFAR10\",\n",
        "    \"INATURALIST_2017\": \"iNaturalist 2017\",\n",
        "    \"INATURALIST_2018\": \"iNaturalist 2018\"\n",
        "}\n",
        "\n",
        "RESNET_TYPE = \"32\"  #@param [\"32\", \"50\", \"101\", \"152\"]\n",
        "BETA = 0.9999  #@param{type:\"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "PRINT_TRAINING = True  #@param{type:\"boolean\"}\n",
        "PRINT_FREQ =   1#@param{type:\"integer\"}\n",
        "DRAW_PLOTS = False  #@param{type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "USE_GOOGLE_DRIVE = True  #@param{type:\"boolean\"}\n",
        "MODELS_PATH =\"/content/drive/MyDrive/Colab Notebooks/cb_loss_resnet/trained_models/\"  #@param{type:\"string\"}\n",
        "SAVE_MODELS = True  #@param{type:\"boolean\"}\n",
        "LOAD_MODELS = False  #@param{type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "TRAIN_FOCAL = True  #@param{type:\"boolean\"}\n",
        "TRAIN_SIGMOID = True  #@param{type:\"boolean\"}\n",
        "TRAIN_SOFTMAX = True  #@param{type:\"boolean\"}\n",
        "TRAIN_CB_FOCAL = True  #@param{type:\"boolean\"}\n",
        "TRAIN_CB_SIGMOID = True  #@param{type:\"boolean\"}\n",
        "TRAIN_CB_SOFTMAX = True  #@param{type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown (Accept prediction if one of the top ACCURACY_TOP guesses is correct)\n",
        "ACCURACY_TOP = 1  #@param {type:\"slider\", min:1, max:9, step:1}\n",
        "TEST_FOCAL = True  #@param{type:\"boolean\"}\n",
        "TEST_SIGMOID = True  #@param{type:\"boolean\"}\n",
        "TEST_SOFTMAX = True  #@param{type:\"boolean\"}\n",
        "TEST_CB_FOCAL = True  #@param{type:\"boolean\"}\n",
        "TEST_CB_SIGMOID = True  #@param{type:\"boolean\"}\n",
        "TEST_CB_SOFTMAX = True  #@param{type:\"boolean\"}\n",
        "\n",
        "if USE_GOOGLE_DRIVE and not MODELS_PATH.startswith(\"/content/drive/\"):\n",
        "  raise RuntimeError('MODELS_PATH should start with \"/content/drive/\"' + \\\n",
        "    ' since USE_GOOGLE_DRIVE is True')\n",
        "\n",
        "if not USE_GOOGLE_DRIVE and MODELS_PATH.startswith(\"/content/drive/\"):\n",
        "  print(\"WARNING: USE_GOOGLE_DRIVE is False but MODELS_PATH starts with\",\n",
        "        '\"/content/drive/\"')\n",
        "\n",
        "if LOAD_MODELS: SAVE_MODELS = False\n",
        "\n",
        "if PRINT_FREQ < 1: PRINT_FREQ = 1\n",
        "\n",
        "if BETA < 0:\n",
        "  BETA = 0\n",
        "elif BETA > 1:\n",
        "  BETA = 1\n",
        "\n",
        "ACCURACY_TOP = int(ACCURACY_TOP)\n",
        "if ACCURACY_TOP < 1:\n",
        "  ACCURACY_TOP = 1\n",
        "elif ACCURACY_TOP > 9:\n",
        "  ACCURACY_TOP = 9\n",
        "\n",
        "if CIFAR_IMB_FACTOR < 10:\n",
        "  CIFAR_IMB_FACTOR = 10\n",
        "elif CIFAR_IMB_FACTOR > 200:\n",
        "  CIFAR_IMB_FACTOR = 200\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCBGvY681tu9",
        "outputId": "8b4a307c-c7e2-4b75-d8de-f43b4b5c4bb3"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from numpy.random import RandomState, SeedSequence, MT19937\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from typing import Any, Callable, Optional, Tuple\n",
        "\n",
        "if USE_GOOGLE_DRIVE:\n",
        "  from google.colab import drive\n",
        "  drive.mount(\"/content/drive\")\n",
        "\n",
        "if DRAW_PLOTS:\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"Using\", torch.cuda.device_count(), \"GPU device(s).\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    MULTI_GPU = False\n",
        "    print(\"Using CPU.\")\n",
        "\n",
        "# For debugging:\n",
        "#torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "class CIFAR10LT(datasets.CIFAR10):\n",
        "  cls_cnt = 10\n",
        "\n",
        "  def __init__(\n",
        "    self,\n",
        "    root: str,\n",
        "    imb_factor=100,  # largest cls. / smallest cls. sample counts\n",
        "    train: bool = True,\n",
        "    transform: Optional[Callable] = None,\n",
        "    target_transform: Optional[Callable] = None,\n",
        "    download: bool = False\n",
        "  ) -> None:\n",
        "    \n",
        "    super().__init__(\n",
        "        root,\n",
        "        train,\n",
        "        transform,\n",
        "        target_transform,\n",
        "        download\n",
        "    )\n",
        "\n",
        "    self.rs = RandomState(MT19937(SeedSequence()))\n",
        "\n",
        "    img_num_list = self.get_img_cnt_per_cls(self.cls_cnt, imb_factor)\n",
        "    self.generate_imb_data(img_num_list)\n",
        "\n",
        "  def get_img_cnt_per_cls(self, cls_cnt, imb_factor):\n",
        "    \"\"\"Return the image count per class required to create class imbalance.\n",
        "\n",
        "    Args:\n",
        "      cls_cnt: Number of classes\n",
        "      imb_factor: Imbalance factor (Largest / Smallest class sizes)\n",
        "    \"\"\"\n",
        "\n",
        "    img_max = len(self.data) / cls_cnt\n",
        "    img_cnt_per_cls = []\n",
        "\n",
        "    for cls_index in range(cls_cnt):\n",
        "      img_cnt_per_cls.append(int(\n",
        "          img_max * ((1/imb_factor)**(cls_index / (cls_cnt - 1)))\n",
        "      ))\n",
        "    \n",
        "    return img_cnt_per_cls\n",
        "  \n",
        "  def generate_imb_data(self, img_cnt_per_cls):\n",
        "    new_data = []\n",
        "    new_targets = []\n",
        "\n",
        "    targets_np = np.array(self.targets, dtype=np.int64)\n",
        "    classes = np.unique(targets_np)\n",
        "\n",
        "    self.cnt_per_cls_dict = dict()\n",
        "\n",
        "    for cls, img_cnt in zip(classes, img_cnt_per_cls):\n",
        "      self.cnt_per_cls_dict[cls] = img_cnt\n",
        "      i = np.where(targets_np == cls)[0]\n",
        "      \n",
        "      self.rs.shuffle(i)\n",
        "      selected_i = i[:img_cnt]\n",
        "      \n",
        "      new_data.append(self.data[selected_i, ...])\n",
        "      new_targets.extend([cls] * img_cnt)\n",
        "    \n",
        "    new_data = np.vstack(new_data)\n",
        "\n",
        "    self.data = new_data\n",
        "    self.targets = new_targets\n",
        "\n",
        "  def get_cls_cnt_list(self):\n",
        "    \"\"\"Return the current (imbalanced) image count per class.\"\"\"\n",
        "    cls_cnt_list = []\n",
        "\n",
        "    for i in range(self.cls_cnt):\n",
        "      cls_cnt_list.append(self.cnt_per_cls_dict[i])\n",
        "    \n",
        "    return cls_cnt_list\n",
        "\n",
        "\n",
        "class INaturalist(Dataset):\n",
        "  def __init__(\n",
        "    self,\n",
        "    root: str,\n",
        "    annotations: str,\n",
        "    version: str=\"2017\",\n",
        "    transform: Optional[Callable]=None,\n",
        "    target_transform: Optional[Callable]=None,\n",
        "  ) -> None:\n",
        "    if version not in [\"2017\", \"2018\"]:\n",
        "      raise RuntimeError(\"version argument must be either '2017' or '2018'.\")\n",
        "\n",
        "    self.root = root\n",
        "    self.version = version\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "    self.class_cnt = 5089 if version == \"2017\" else 8142\n",
        "\n",
        "    self.to_tensor = transforms.ToTensor()\n",
        "\n",
        "    with open(annotations) as f:\n",
        "      ann_data = json.load(f)\n",
        "\n",
        "    self.imgs = [a[\"file_name\"] for a in ann_data[\"images\"]]\n",
        "    #self.ids = [a[\"id\"] for a in ann_data[\"images\"]]\n",
        "\n",
        "    # self.classes holds the label of each image in the corresponding index\n",
        "    if \"annotations\" in ann_data.keys():\n",
        "      self.classes = [a[\"category_id\"] for a in ann_data[\"annotations\"]]\n",
        "    else:\n",
        "      # If not given, set class labels to 0\n",
        "      self.classes = [0] * len(self.imgs)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imgs)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if self.root.endswith(\"/\"):\n",
        "      path = self.root + self.imgs[idx]\n",
        "    else:\n",
        "      path = self.root + \"/\" + self.imgs[idx]\n",
        "    \n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    \n",
        "    #im_id = self.ids[idx]\n",
        "    target = self.classes[idx]  # label of the image (i.e. species ID)\n",
        "\n",
        "    if self.transform is not None:\n",
        "      img = self.transform(img)\n",
        "    else:\n",
        "      img = self.to_tensor(img)\n",
        "    \n",
        "    if self.target_transform is not None:\n",
        "      target = self.target_transform(target)\n",
        "\n",
        "    return img, target\n",
        "\n",
        "  def get_cls_cnt_list(self):\n",
        "    cls_cnt_list = [0] * self.class_cnt\n",
        "\n",
        "    for i in self.classes: cls_cnt_list[i] += 1\n",
        "\n",
        "    return cls_cnt_list\n",
        "\n",
        "\n",
        "class ResNet32(nn.Module):\n",
        "  def __init__(self, num_layers=32, num_classes=10):\n",
        "    super(ResNet32, self).__init__()\n",
        "\n",
        "    self.n = (num_layers - 2) // 6\n",
        "    self.num_classes = num_classes\n",
        "    self.filters = [16, 16, 32, 64]\n",
        "    self.strides = [1, 2, 2]\n",
        "\n",
        "    self.conv = nn.Conv2d(3, 16, 3, 1, padding='same', bias= False)\n",
        "    self.norm = nn.BatchNorm2d(16)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    Layers = []\n",
        "\n",
        "    for i in range(3):\n",
        "      for j in range(self.n):\n",
        "        if j == 0:\n",
        "          in_filter = self.filters[i]\n",
        "          stride = self.strides[i]\n",
        "\n",
        "        else:\n",
        "          in_filter = self.filters[i+1]\n",
        "          stride = 1\n",
        "        \n",
        "        out_filter = self.filters[i+1]\n",
        "\n",
        "        Layers.append(ResBlock(in_filter, out_filter, stride))\n",
        "\n",
        "    self.sequential = nn.Sequential(*Layers)\n",
        "\n",
        "    def global_avg_pool(x):\n",
        "      return x.mean(axis= [2,3])\n",
        "\n",
        "    self.global_pool = global_avg_pool\n",
        "    self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = self.norm(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.sequential(x)\n",
        "    x = self.global_pool(x)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "  def __init__(self, in_filter, out_filter, stride):\n",
        "    super(ResBlock, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_filter, out_filter, 3, stride, padding=1, bias= False)\n",
        "    self.norm1 = nn.BatchNorm2d(out_filter)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.conv2 = nn.Conv2d(out_filter, out_filter, 3, 1, padding='same', bias= False)\n",
        "    self.norm2 = nn.BatchNorm2d(out_filter)\n",
        "\n",
        "    self.avg_pool = None\n",
        "\n",
        "    def get_Padding(padding):\n",
        "      pad = padding\n",
        "      def Padding(x):\n",
        "        return F.pad(x, padding)\n",
        "      \n",
        "      return Padding\n",
        "\n",
        "    if (in_filter != out_filter):\n",
        "      self.avg_pool = nn.AvgPool2d(stride, stride)\n",
        "      self.pool_padding = get_Padding([0,1,0,1])\n",
        "      pad = (out_filter - in_filter) // 2\n",
        "      self.channel_padding = get_Padding([0,0,0,0,pad,pad])\n",
        "\n",
        "  def forward(self, x):\n",
        "    with torch.no_grad():\n",
        "      x_orig = x\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = self.norm1(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.norm2(x)\n",
        "\n",
        "    if self.avg_pool is not None:\n",
        "      x_orig = self.pool_padding(x_orig)\n",
        "      x_orig = self.avg_pool(x_orig)\n",
        "      x_orig = self.channel_padding(x_orig)\n",
        "\n",
        "    x += x_orig\n",
        "\n",
        "    x = self.relu(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_weights(class_sizes, beta=0, device=\"cpu\"):\n",
        "  \"\"\"Get normalized weight per class.\"\"\"\n",
        "\n",
        "  class_cnt = len(class_sizes)\n",
        "  class_sizes = torch.as_tensor(\n",
        "    class_sizes,\n",
        "    dtype=torch.float32,\n",
        "    device=device\n",
        "  )\n",
        "  \n",
        "  weights = torch.as_tensor(\n",
        "    [1 - beta] * class_cnt,\n",
        "    dtype=torch.float32,\n",
        "    device=device\n",
        "  )\n",
        "  \n",
        "  weights = torch.div(\n",
        "      weights, 1 - torch.pow(beta, class_sizes)\n",
        "  ).to(device)\n",
        "  \n",
        "  # Normalize the weights\n",
        "  weights = torch.mul(weights, class_cnt / torch.sum(weights)).to(device)\n",
        "\n",
        "  return weights.double()\n",
        "\n",
        "\n",
        "def focal_loss(z, lbl, alpha=None, gamma=0):\n",
        "  \"\"\"Return the focal loss tensor of shape [batch_size] for given model & lbl.s.\n",
        "\n",
        "  Args:\n",
        "    z: Predictions tensor of shape [batch_size, label_count], output of ResNet\n",
        "    lbl: Labels tensor of shape [batch_size]\n",
        "    alpha: Class balance weights tensor of shape [lable_count]\n",
        "    gamma: Focal loss parameter (if 0, loss is equivalent to sigmoid ce. loss)\n",
        "  \"\"\"\n",
        "\n",
        "  z = z.double()\n",
        "  \n",
        "  batch_size = z.shape[0]  # Not a constant: the last batch might be smaller\n",
        "  lbl_cnt = z.shape[1]\n",
        "\n",
        "  # \"Decode\" labels tensor to make its shape [batch_size, label_count]:\n",
        "  lbl = F.one_hot(lbl, num_classes=lbl_cnt)\n",
        "\n",
        "  if alpha is None:\n",
        "    alpha = torch.as_tensor([1] * batch_size, device=device)\n",
        "  else:\n",
        "    # Get weights for each image in batch\n",
        "    alpha = (alpha * lbl).sum(axis=1)\n",
        "\n",
        "  # TODO: Check if the bool casting is required for torch.where() to work\n",
        "  lbl_bool = lbl.type(torch.bool)\n",
        "\n",
        "  z_t = torch.where(lbl_bool, z, -z).to(device)\n",
        "\n",
        "  sig = nn.Sigmoid()\n",
        "  logsig = nn.LogSigmoid()\n",
        "\n",
        "  p_t = sig(z_t).to(device)\n",
        "  cross_entpy = logsig(z_t).to(device)\n",
        "  \n",
        "  if gamma:\n",
        "    modulator = torch.exp(\n",
        "        -gamma * torch.mul(lbl, z).to(device) - gamma * torch.log1p(torch.exp(-1.0 * z))\n",
        "    )\n",
        "  else:\n",
        "    modulator = 1\n",
        "  \n",
        "  # Sum the value of each class in each batch. The shape is reduced from\n",
        "  #  [batch_size, label_count] to [batch_size].\n",
        "  unweighted_focal_loss = -torch.sum(torch.mul(modulator, cross_entpy), 1).to(\n",
        "    device\n",
        "  )\n",
        "  weighted_focal_loss = torch.mul(alpha, unweighted_focal_loss).to(device)\n",
        "\n",
        "  # Normalize by the positive sample count:\n",
        "  weighted_focal_loss /= torch.sum(lbl)\n",
        "\n",
        "  return torch.sum(weighted_focal_loss)\n",
        "\n",
        "\n",
        "def get_accuracy(test_data:DataLoader, model, class_sizes:[int], calc_avg=True,\n",
        "                 calc_perclass=True, top=1, device=device):\n",
        "  \"\"\"Return a tuple containing the accuracy values of a given model.\n",
        "\n",
        "  The first element of the returned tuple is the average accuracy of the model.\n",
        "  The second element is a tensor containing the accuracy of each class\n",
        "    separately.\n",
        "  \n",
        "  The parameters calc_avg and calc_perclass exist for performance adjustments.\n",
        "  If calc_avg is False, the average accuracy isn't calculated and left as 0.\n",
        "  If calc_perclass is False, the per-class accuracies aren't calculated and left\n",
        "    as 0.\n",
        "  \"\"\"\n",
        "\n",
        "  total_size = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    num_labels = len(class_sizes)\n",
        "\n",
        "    per_class_acc = torch.zeros(num_labels, dtype=torch.float32, device=device)\n",
        "    avg_acc = float(0)\n",
        "\n",
        "    for num_batch, (input, target) in enumerate(test_data):\n",
        "      input = input.double().to(device)\n",
        "      target = target.to(device)\n",
        "      output = model(input).to(device)\n",
        "      \n",
        "      if top == 1:\n",
        "        result = (torch.argmax(output, dim = 1) == target)\n",
        "      else:\n",
        "        result = []\n",
        "        top_preds = np.argpartition(output, -top)[:, -top:]\n",
        "\n",
        "        for i, t in enumerate(target):\n",
        "          result.append(t.item() in top_preds[i])\n",
        "        \n",
        "        result = torch.Tensor(result)\n",
        "\n",
        "      batch_len = result.shape[0]\n",
        "\n",
        "      if calc_avg:\n",
        "        avg_acc += result.sum()\n",
        "\n",
        "      if calc_perclass:\n",
        "        for i in range(batch_len):\n",
        "          per_class_acc[target[i]] += result[i]\n",
        "      \n",
        "      total_size += batch_len\n",
        "      \n",
        "    # Average accuracy of the whole test dataset\n",
        "    if calc_avg: avg_acc /= total_size\n",
        "\n",
        "    if calc_perclass:\n",
        "      for i in range(num_labels):\n",
        "        # Average accuracy of every class separately\n",
        "        per_class_acc[i] /= class_sizes[i]\n",
        "\n",
        "    return (avg_acc.item(), per_class_acc.tolist())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Using 1 GPU device(s).\n",
            "<class 'torch.device'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqpJoaBQ6GKM"
      },
      "source": [
        "# Define Datasets & DataLoaders\n",
        "Run the block below to download and pre-process the datasets, and calculate the weights.\n",
        "\n",
        "If `DATASET` is set to `IMB_CIFAR10`, a long-tailed CIFAR10 dataset will be generated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "9799c7bb53ba4c64a8fbd90be988cdff",
            "c48dcb9bc9244f40bd1bb5c76611b7b2",
            "fb917ed7ee5b44fba9ef3b6bf528cce6",
            "e55e70b50aa34e659bda94931c5a34d2",
            "2844ca90e9314d229d8c87194333ef60",
            "6bf0354c88024b45a464b947f24e6356",
            "895537a5f57945b2bc778d107d49ea28",
            "d785269286b74737a9e9aef8c4b81518",
            "920645b59c174b48a4fa6d8819fa5152",
            "fce111deeb6241a897780073ede28856",
            "5f22352f713e4cc9b6cd0cb7aad741c4"
          ]
        },
        "id": "zqtECnxpYE28",
        "outputId": "9c33097e-0198-4682-f262-8bc6ea38482b"
      },
      "source": [
        "def generate_data(device=device, batch_size=BATCH_SIZE, dataset=DATASET,\n",
        "                  cifar_imb_factor=CIFAR_IMB_FACTOR, inat_32x32=INAT_32X32,\n",
        "                  draw_plots=DRAW_PLOTS, use_gdrive=USE_GOOGLE_DRIVE):\n",
        "  # TODO: Find better jitter, mu and std. values for each dataset\n",
        "  if dataset == \"CIFAR10\":\n",
        "    normalize_mu = (0.4914, 0.4822, 0.4465)\n",
        "    normalize_std = (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "    im_size = 32\n",
        "    pad = 4\n",
        "\n",
        "    #jtr_brightness = 0.4\n",
        "    #jtr_contrast = 0.4\n",
        "    #jtr_saturation = 0.4\n",
        "    #jtr_hue = 0.25\n",
        "  elif dataset == \"IMB_CIFAR10\":\n",
        "    normalize_mu = (0.5, 0.5, 0.5)\n",
        "    normalize_std = (0.5, 0.5, 0.5)\n",
        "\n",
        "    im_size = 32\n",
        "    pad = 4\n",
        "\n",
        "    #jtr_brightness = 0.4\n",
        "    #jtr_contrast = 0.4\n",
        "    #jtr_saturation = 0.4\n",
        "    #jtr_hue = 0.25\n",
        "  elif dataset == \"INATURALIST_2017\":\n",
        "    normalize_mu = (0.5, 0.5, 0.5)\n",
        "    normalize_std = (0.5, 0.5, 0.5)\n",
        "\n",
        "    im_size = 224\n",
        "    pad = 32\n",
        "\n",
        "    #jtr_brightness = 0.4\n",
        "    #jtr_contrast = 0.4\n",
        "    #jtr_saturation = 0.4\n",
        "    #jtr_hue = 0.25\n",
        "  elif dataset == \"INATURALIST_2018\":\n",
        "    normalize_mu = (0.485, 0.456, 0.406)\n",
        "    normalize_std = (0.229, 0.224, 0.225)\n",
        "\n",
        "    im_size = 224\n",
        "    pad = 32\n",
        "\n",
        "    #jtr_brightness = 0.4\n",
        "    #jtr_contrast = 0.4\n",
        "    #jtr_saturation = 0.4\n",
        "    #jtr_hue = 0.25\n",
        "  \n",
        "  train_transforms = transforms.Compose([\n",
        "    transforms.Pad(padding=pad, fill=0, padding_mode=\"constant\"),\n",
        "    transforms.RandomResizedCrop(im_size),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    #transforms.ColorJitter(jtr_brightness, jtr_contrast, jtr_saturation, jtr_hue),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=normalize_mu, std=normalize_std, inplace=True)\n",
        "  ])\n",
        "\n",
        "  test_transforms = transforms.Compose([\n",
        "    transforms.CenterCrop(im_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=normalize_mu, std=normalize_std)  # TODO: Should test normalization be in place too?\n",
        "  ])\n",
        "\n",
        "\n",
        "  if dataset == \"CIFAR10\":\n",
        "    train_ds = datasets.CIFAR10(\n",
        "        \"datasets/cifar10\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=train_transforms\n",
        "    )\n",
        "\n",
        "    test_ds = datasets.CIFAR10(\n",
        "      \"datasets/cifar10\",\n",
        "      train=False,\n",
        "      download=True,\n",
        "      transform=test_transforms\n",
        "    )\n",
        "  elif dataset == \"IMB_CIFAR10\":  # Long-Tailed CIFAR10\n",
        "    train_ds = CIFAR10LT(\n",
        "      \"datasets/cifar10\",\n",
        "      imb_factor=cifar_imb_factor,\n",
        "      train=True,\n",
        "      download=True,\n",
        "      transform=train_transforms\n",
        "    )\n",
        "\n",
        "    test_ds = datasets.CIFAR10(  # Test set is not imbalanced\n",
        "        \"datasets/cifar10\",\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=test_transforms\n",
        "    )\n",
        "  elif dataset == \"INATURALIST_2017\":\n",
        "    \"\"\"\n",
        "    train_ds = INaturalist(\n",
        "        \"datasets/inat2017\",\n",
        "        \"/content/drive/MyDrive/Colab Notebooks/cb_loss_resnet/datasets/inat2017/train2017.json\" if use_gdrive else \"datasets/inat2017/train2017.json\",\n",
        "        version=\"2017\",\n",
        "        transform=train_transforms\n",
        "    )\n",
        "\n",
        "    test_ds = INaturalist(\n",
        "        \"datasets/inat2017/test2017\",\n",
        "        \"/content/drive/MyDrive/Colab Notebooks/cb_loss_resnet/datasets/inat2017/test2017.json\" if use_gdrive else \"datasets/inat2017/test2017.json\",\n",
        "        version=\"2017\",\n",
        "        transform=test_transforms\n",
        "    )\n",
        "    \"\"\"\n",
        "\n",
        "    # To use pre-transformed datasets:\n",
        "    if use_gdrive:\n",
        "      inat_path =  \"/content/drive/MyDrive/Colab Notebooks/cb_loss_resnet/datasets/inat2017_transf\" + (\"_32/\" if inat_32x32 else \"\")\n",
        "    else:\n",
        "      inat_path =  \"datasets/inat2017_transf\" + (\"_32/\" if inat_32x32 else \"/\")\n",
        "    \n",
        "    train_ds = INaturalist(\n",
        "        inat_path,\n",
        "        inat_path + \"train2017.json\",\n",
        "        version=\"2017\"\n",
        "    )\n",
        "\n",
        "    test_ds = INaturalist(\n",
        "        inat_path + \"test2017/\",\n",
        "        inat_path + \"test2017.json\",\n",
        "        version=\"2017\"\n",
        "    )\n",
        "  elif dataset == \"INATURALIST_2018\":\n",
        "    \"\"\"\n",
        "    train_ds = INaturalist(\n",
        "        \"datasets/inat2018\",\n",
        "        \"/content/drive/MyDrive/Colab Notebooks/cb_loss_resnet/datasets/inat2018/train2018.json\" if use_gdrive else \"datasets/inat2018/train2018.json\",\n",
        "        version=\"2018\",\n",
        "        transform=train_transforms\n",
        "    )\n",
        "\n",
        "    test_ds = INaturalist(\n",
        "        \"datasets/inat2018\",\n",
        "        \"/content/drive/MyDrive/Colab Notebooks/cb_loss_resnet/datasets/inat2018/test2018.json\" if use_gdrive else \"datasets/inat2018/test2018.json\",\n",
        "        version=\"2018\",\n",
        "        transform=test_transforms\n",
        "    )\n",
        "    \"\"\"\n",
        "\n",
        "    # To use pre-transformed datasets:\n",
        "    if use_gdrive:\n",
        "      inat_path =  \"/content/drive/MyDrive/Colab Notebooks/cb_loss_resnet/datasets/inat2018_transf\" + (\"_32/\" if inat_32x32 else \"\")\n",
        "    else:\n",
        "      inat_path =  \"datasets/inat2018_transf\" + (\"_32/\" if inat_32x32 else \"/\")\n",
        "    \n",
        "    train_ds = INaturalist(\n",
        "        inat_path,\n",
        "        inat_path + \"train2018.json\",\n",
        "        version=\"2018\"\n",
        "    )\n",
        "\n",
        "    test_ds = INaturalist(\n",
        "        inat_path,\n",
        "        inat_path + \"test2018.json\",\n",
        "        version=\"2018\"\n",
        "    )\n",
        "\n",
        "\n",
        "  train_dl = DataLoader(\n",
        "      train_ds,\n",
        "      batch_size=batch_size,\n",
        "      num_workers=2,\n",
        "      shuffle=True\n",
        "  )\n",
        "  \n",
        "  test_dl = DataLoader(\n",
        "      test_ds,\n",
        "      batch_size=batch_size,\n",
        "      num_workers=2\n",
        "  )\n",
        "\n",
        "  class_cnt = 0\n",
        "\n",
        "  if dataset == \"CIFAR10\":\n",
        "    class_cnt = 10\n",
        "    train_class_sizes = [5000] * class_cnt\n",
        "    test_class_sizes = [1000] * class_cnt\n",
        "  elif dataset == \"IMB_CIFAR10\":\n",
        "    class_cnt = 10\n",
        "    train_class_sizes = train_ds.get_cls_cnt_list()    \n",
        "    test_class_sizes = [1000] * class_cnt\n",
        "  elif dataset == \"INATURALIST_2017\":\n",
        "    class_cnt = 5089\n",
        "    train_class_sizes = train_ds.get_cls_cnt_list()    \n",
        "    test_class_sizes = test_ds.get_cls_cnt_list()\n",
        "  elif dataset == \"INATURALIST_2018\":\n",
        "    class_cnt = 8142\n",
        "    train_class_sizes = train_ds.get_cls_cnt_list()    \n",
        "    test_class_sizes = test_ds.get_cls_cnt_list()\n",
        "\n",
        "  print(\"Number of training samples:\")\n",
        "  print(np.array(train_class_sizes))  # Numpy array for cleaner output\n",
        "\n",
        "  if draw_plots:\n",
        "    x = np.arange(class_cnt)\n",
        "    fig, axs = plt.subplots(2, constrained_layout=True)\n",
        "    \n",
        "    fig.set_figheight(12)\n",
        "    fig.set_figwidth(16)\n",
        "\n",
        "    fig.suptitle('Class Sizes & Weights for ' + DSET_NAMES[dataset])\n",
        "    \n",
        "    axs[0].set_title('Size Per Class (Unsorted)')\n",
        "    axs[0].plot(x, train_class_sizes)\n",
        "    \n",
        "    axs[1].set_title('Size Per Class (Sorted)')\n",
        "    axs[1].plot(x, sorted(train_class_sizes, reverse=True))\n",
        "    \n",
        "    if not use_gdrive:\n",
        "      plt.savefig(f\"./plots/{dataset.lower()}_size_per_class.png\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "  return train_dl, test_dl, class_cnt, train_class_sizes, test_class_sizes\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  train_dl, test_dl, class_cnt, train_class_sizes, test_class_sizes = generate_data()\n",
        "  \n",
        "  weights = get_weights(train_class_sizes, BETA, device)\n",
        "  weights.requires_grad = False\n",
        "\n",
        "  print(\"Got weights:\")\n",
        "  print(np.array(weights.tolist()))  # Numpy array for cleaner output\n",
        "\n",
        "  if draw_plots:\n",
        "    x = np.arange(class_cnt)\n",
        "    fig, axs = plt.subplots(2, constrained_layout=True)\n",
        "\n",
        "    fig.set_figheight(12)\n",
        "    fig.set_figwidth(16)\n",
        "\n",
        "    axs[0].set_title('Weight Per Class (Unsorted)')\n",
        "    axs[0].plot(x, weights.tolist())\n",
        "\n",
        "    axs[1].set_title('Weight Per Class (Sorted)')\n",
        "    axs[1].plot(x, sorted(weights.tolist()))\n",
        "\n",
        "    if not use_gdrive:\n",
        "      plt.savefig(f\"./plots/{dataset.lower()}_weight_per_class.png\")\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to datasets/cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9799c7bb53ba4c64a8fbd90be988cdff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting datasets/cifar10/cifar-10-python.tar.gz to datasets/cifar10\n",
            "Files already downloaded and verified\n",
            "Number of training samples:\n",
            "[5000 3237 2096 1357  878  568  368  238  154  100]\n",
            "Got weights:\n",
            "[0.08903377 0.12668113 0.18526001 0.27606049 0.41675401 0.63441569\n",
            " 0.9695372  1.48944986 2.29224944 3.52055836]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "4-3O7TQyQmDR",
        "outputId": "a619c873-36f1-4aa8-b411-cce71a69b3af"
      },
      "source": [
        "# To view an example image:\n",
        "#plt.imshow(next(iter(train_dl))[0][0].permute(1,2,0))\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7247233650>"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2asdyYT_6OHp"
      },
      "source": [
        "# Define and train ResNets\n",
        "If `SAVE_MODELS` is enabled, the models are saved in the local storage (or Google Drive if `USE_GOOGLE_DRIVE` is enabled) when they are trained.\n",
        "\n",
        "Likewise, they can be loaded from the local storage (or Google Drive if `USE_GOOGLE_DRIVE` is enabled) with `LOAD_MODELS`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84OUrYkWYFDw"
      },
      "source": [
        "def train_models(train_dl, class_cnt, weights, device=device,\n",
        "                epoch_cnt=EPOCH_CNT, multi_gpu=MULTI_GPU, dataset=DATASET,\n",
        "                resnet_type=RESNET_TYPE, print_training=PRINT_TRAINING,\n",
        "                print_freq=PRINT_FREQ, draw_plots=DRAW_PLOTS,\n",
        "                use_gdrive=USE_GOOGLE_DRIVE, models_path=MODELS_PATH,\n",
        "                save_models=SAVE_MODELS, load_models=LOAD_MODELS,\n",
        "                train_focal=TRAIN_FOCAL, train_sigmoid=TRAIN_SIGMOID,\n",
        "                train_softmax=TRAIN_SOFTMAX, train_cb_focal=TRAIN_CB_FOCAL,\n",
        "                train_cb_sigmoid=TRAIN_CB_SIGMOID,\n",
        "                train_cb_softmax=TRAIN_CB_SOFTMAX, test_focal=test_focal,\n",
        "                test_sigmoid=TEST_SIGMOID, test_softmax=TEST_SOFTMAX,\n",
        "                test_cb_focal=TEST_CB_FOCAL, test_cb_sigmoid=TEST_CB_SIGMOID,\n",
        "                test_cb_softmax=TEST_CB_SOFTMAX):\n",
        "  if resnet_type == \"32\":\n",
        "    rn = ResNet32\n",
        "  elif resnet_type == \"50\":\n",
        "    rn = models.resnet50\n",
        "  elif resnet_type == \"101\":\n",
        "    rn = models.resnet101\n",
        "  elif resnet_type == \"152\":\n",
        "    rn = models.resnet152\n",
        "  else:\n",
        "    raise ValueError(\"Invalid resnet_type\")\n",
        "\n",
        "  param_list = []\n",
        "\n",
        "  rn_focal = None\n",
        "  rn_sigmoid = None\n",
        "  rn_softmax = None\n",
        "  rn_cb_focal = None\n",
        "  rn_cb_sigmoid = None\n",
        "  rn_cb_softmax = None\n",
        "\n",
        "  # The \"state\" var. provides the same initial state for every model\n",
        "  state = None\n",
        "\n",
        "  if train_focal: \n",
        "    rn_focal = rn(num_classes=class_cnt).double()\n",
        "    if multi_gpu: rn_focal = nn.DataParallel(rn_focal)\n",
        "    rn_focal = rn_focal.to(device)\n",
        "\n",
        "    param_list.append({'params': rn_focal.parameters()})\n",
        "\n",
        "    state = rn_focal.state_dict()\n",
        "  if train_sigmoid: \n",
        "    rn_sigmoid = rn(num_classes=class_cnt).double()\n",
        "    if multi_gpu: rn_sigmoid = nn.DataParallel(rn_sigmoid)\n",
        "    rn_sigmoid = rn_sigmoid.to(device)\n",
        "\n",
        "    param_list.append({'params': rn_sigmoid.parameters()})\n",
        "\n",
        "    if state:\n",
        "      rn_sigmoid.load_state_dict(state)\n",
        "    else:\n",
        "      state = rn_sigmoid.state_dict()\n",
        "  if train_softmax:\n",
        "    rn_softmax = rn(num_classes=class_cnt).double()\n",
        "    if multi_gpu: rn_softmax = nn.DataParallel(rn_softmax)\n",
        "    rn_softmax = rn_softmax.to(device)\n",
        "\n",
        "    param_list.append({'params': rn_softmax.parameters()})\n",
        "\n",
        "    if state:\n",
        "      rn_softmax.load_state_dict(state)\n",
        "    else:\n",
        "      state = rn_softmax.state_dict()\n",
        "  if train_cb_focal:\n",
        "    rn_cb_focal = rn(num_classes=class_cnt).double()\n",
        "    if multi_gpu: rn_cb_focal = nn.DataParallel(rn_cb_focal)\n",
        "    rn_cb_focal = rn_cb_focal.to(device)\n",
        "\n",
        "    param_list.append({'params': rn_cb_focal.parameters()})\n",
        "\n",
        "    if state:\n",
        "      rn_cb_focal.load_state_dict(state)\n",
        "    else:\n",
        "      state = rn_cb_focal.state_dict()\n",
        "  if train_cb_sigmoid:\n",
        "    rn_cb_sigmoid = rn(num_classes=class_cnt).double()\n",
        "    if multi_gpu: rn_cb_sigmoid = nn.DataParallel(rn_cb_sigmoid)\n",
        "    rn_cb_sigmoid = rn_cb_sigmoid.to(device)\n",
        "\n",
        "    param_list.append({'params': rn_cb_sigmoid.parameters()})\n",
        "\n",
        "    if state:\n",
        "      rn_cb_sigmoid.load_state_dict(state)\n",
        "    else:\n",
        "      state = rn_cb_sigmoid.state_dict()\n",
        "  if train_cb_softmax:\n",
        "    rn_cb_softmax = rn(num_classes=class_cnt).double()\n",
        "    if multi_gpu: rn_cb_softmax = nn.DataParallel(rn_cb_softmax)\n",
        "    rn_cb_softmax = rn_cb_softmax.to(device)\n",
        "\n",
        "    param_list.append({'params': rn_cb_softmax.parameters()})\n",
        "\n",
        "    if state:\n",
        "      rn_cb_softmax.load_state_dict(state)\n",
        "\n",
        "  if load_models:\n",
        "    # Assuming the file exists for each model that will be tested:\n",
        "    # TODO: Catch loading errors in try-except blocks\n",
        "\n",
        "    if test_focal:\n",
        "      rn_focal.load_state_dict(\n",
        "        torch.load(models_path + f\"rn{resnet_type}_focal_{dataset}.pth\",\n",
        "                   map_location=device)\n",
        "      )\n",
        "      print(f\"Loaded model (ResNet-{resnet_type} focal, {DSET_NAMES[dataset]}):\",\n",
        "            models_path + f\"rn{resnet_type}_focal_{dataset}.pth\")\n",
        "    \n",
        "    if test_sigmoid:\n",
        "      rn_sigmoid.load_state_dict(\n",
        "        torch.load(models_path + f\"rn{resnet_type}_sigmoid_{dataset}.pth\",\n",
        "                   map_location=device)\n",
        "      )\n",
        "      print(f\"Loaded model (ResNet-{resnet_type} sigmoid, {DSET_NAMES[dataset]}):\",\n",
        "            models_path + f\"rn{resnet_type}_sigmoid_{dataset}.pth\")\n",
        "\n",
        "    if test_softmax:\n",
        "      rn_softmax.load_state_dict(\n",
        "        torch.load(models_path + f\"rn{resnet_type}_softmax_{dataset}.pth\",\n",
        "                   map_location=device)\n",
        "      )\n",
        "      print(f\"Loaded model (ResNet-{resnet_type} softmax, {DSET_NAMES[dataset]}):\",\n",
        "            models_path + f\"rn{resnet_type}_softmax_{dataset}.pth\")\n",
        "\n",
        "    if test_cb_focal:\n",
        "      rn_cb_focal.load_state_dict(\n",
        "        torch.load(models_path + f\"rn{resnet_type}_cb_focal_{dataset}.pth\",\n",
        "                   map_location=device)\n",
        "      )\n",
        "      print(f\"Loaded model (ResNet-{resnet_type} cb. focal, {DSET_NAMES[dataset]}):\",\n",
        "            models_path + f\"rn{resnet_type}_cb_focal_{dataset}.pth\")\n",
        "\n",
        "    if test_cb_sigmoid:\n",
        "      rn_cb_sigmoid.load_state_dict(\n",
        "        torch.load(models_path + f\"rn{resnet_type}_cb_sigmoid_{dataset}.pth\",\n",
        "                   map_location=device)\n",
        "      )\n",
        "      print(f\"Loaded model (ResNet-{resnet_type} cb. sigmoid, {DSET_NAMES[dataset]}):\",\n",
        "            models_path + f\"rn{resnet_type}_cb_sigmoid_{dataset}.pth\")\n",
        "\n",
        "    if test_cb_softmax:\n",
        "      rn_cb_softmax.load_state_dict(\n",
        "        torch.load(models_path + f\"rn{resnet_type}_cb_softmax_{dataset}.pth\",\n",
        "                   map_location=device)\n",
        "      )\n",
        "      print(f\"Loaded model (ResNet-{resnet_type} cb. softmax, {DSET_NAMES[dataset]}):\",\n",
        "            models_path + f\"rn{resnet_type}_cb_softmax_{dataset}.pth\")\n",
        "  else:\n",
        "    # Initialize FC biases of models trained with sigmoid and focal losses\n",
        "    #   to avoid instability at the beginning of the training\n",
        "    pi = torch.tensor(0.1, dtype=torch.double)\n",
        "    b = -torch.log((1 - pi) / pi)\n",
        "    \n",
        "    if multi_gpu:\n",
        "      if train_focal: rn_focal.module.fc.bias.data.fill_(b)\n",
        "      if train_sigmoid: rn_sigmoid.module.fc.bias.data.fill_(b)\n",
        "      if train_cb_focal: rn_cb_focal.module.fc.bias.data.fill_(b)\n",
        "      if train_cb_sigmoid: rn_cb_sigmoid.module.fc.bias.data.fill_(b)\n",
        "    else:\n",
        "      if train_focal: rn_focal.fc.bias.data.fill_(b)\n",
        "      if train_sigmoid: rn_sigmoid.fc.bias.data.fill_(b)\n",
        "      if train_cb_focal: rn_cb_focal.fc.bias.data.fill_(b)\n",
        "      if train_cb_sigmoid: rn_cb_sigmoid.fc.bias.data.fill_(b)\n",
        "\n",
        "    # TODO: Disable optimizer's weight decay for the biases\n",
        "    #rn_focal.fc.bias.requires_grad_(False)\n",
        "    #rn_sigmoid.fc.bias.requires_grad_(False)\n",
        "    #rn_cb_focal.fc.bias.requires_grad_(False)\n",
        "    #rn_cb_sigmoid.fc.bias.requires_grad_(False)\n",
        "\n",
        "    # Initialize ce. loss models' FC biases with 0\n",
        "    if multi_gpu:\n",
        "      if train_softmax: rn_softmax.module.fc.bias.data.fill_(0)\n",
        "      if train_cb_softmax: rn_cb_softmax.module.fc.bias.data.fill_(0)\n",
        "    else:\n",
        "      if train_softmax: rn_softmax.fc.bias.data.fill_(0)\n",
        "      if train_cb_softmax: rn_cb_softmax.fc.bias.data.fill_(0)\n",
        "    \n",
        "    optimizer = torch.optim.SGD(\n",
        "      param_list,\n",
        "      lr=0,  # Will be graudally increased to 0.1 in 5 epochs\n",
        "      momentum=0.9,\n",
        "      weight_decay=2e-4\n",
        "    )\n",
        "\n",
        "    if train_softmax: cel = nn.CrossEntropyLoss()\n",
        "    if train_cb_softmax: \n",
        "      #print(\"Passing weights:\", weights)\n",
        "      cb_cel = nn.CrossEntropyLoss(weight=weights, reduction=\"sum\")\n",
        "\n",
        "    if draw_plots:\n",
        "      if train_focal: history_loss_focal = []\n",
        "      if train_sigmoid: history_loss_sigmoid = []\n",
        "      if train_softmax: history_loss_softmax = []\n",
        "      if train_cb_focal: history_loss_cb_focal = []\n",
        "      if train_cb_sigmoid: history_loss_cb_sigmoid = []\n",
        "      if train_cb_softmax: history_loss_cb_softmax = []\n",
        "\n",
        "    print(f\"Starting training with {DSET_NAMES[dataset]} dataset,\",\n",
        "      f\"ResNet-{resnet_type} models.\")\n",
        "    try:\n",
        "      for epoch in range(epoch_cnt):\n",
        "        if train_focal: total_loss_focal = 0\n",
        "        if train_sigmoid: total_loss_sigmoid = 0\n",
        "        if train_softmax: total_loss_softmax = 0\n",
        "        if train_cb_focal: total_loss_cb_focal = 0\n",
        "        if train_cb_sigmoid: total_loss_cb_sigmoid = 0\n",
        "        if train_cb_softmax: total_loss_cb_softmax = 0\n",
        "        \n",
        "        if epoch < 5:\n",
        "          # Linear warm-up of learning rate from 0 to 0.1 in the first 5 epochs\n",
        "          for g in optimizer.param_groups:\n",
        "            g[\"lr\"] += 0.02\n",
        "        elif epoch in [159, 179]:\n",
        "          # Decay learning rate by 0.01 at 160th and 180th epochs\n",
        "          for g in optimizer.param_groups:\n",
        "            g[\"lr\"] *= 0.01\n",
        "\n",
        "        for i, (input, target) in enumerate(train_dl):\n",
        "          input = input.double().to(device)\n",
        "          target = target.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          if train_focal:\n",
        "            loss_focal = focal_loss(\n",
        "                rn_focal(input),\n",
        "                target,\n",
        "                gamma=0.5\n",
        "            )\n",
        "\n",
        "            loss_focal.backward()\n",
        "            total_loss_focal += loss_focal.item()\n",
        "          \n",
        "          if train_sigmoid:\n",
        "            loss_sigmoid = focal_loss(\n",
        "                rn_sigmoid(input),\n",
        "                target\n",
        "            )\n",
        "\n",
        "            loss_sigmoid.backward()\n",
        "            total_loss_sigmoid += loss_sigmoid.item()\n",
        "\n",
        "          if train_softmax:\n",
        "            loss_softmax = cel(\n",
        "                rn_softmax(input),\n",
        "                target\n",
        "            )\n",
        "            \n",
        "            loss_softmax.backward()\n",
        "            total_loss_softmax += loss_softmax.item()\n",
        "\n",
        "          if train_cb_focal:\n",
        "            loss_cb_focal = focal_loss(\n",
        "                rn_cb_focal(input),\n",
        "                target,\n",
        "                alpha=weights,\n",
        "                gamma=0.5\n",
        "            )\n",
        "\n",
        "            loss_cb_focal.backward()\n",
        "            total_loss_cb_focal += loss_cb_focal.item()\n",
        "\n",
        "          if train_cb_sigmoid:\n",
        "            loss_cb_sigmoid = focal_loss(\n",
        "                rn_cb_sigmoid(input),\n",
        "                target,\n",
        "                alpha=weights\n",
        "            )\n",
        "\n",
        "            loss_cb_sigmoid.backward()\n",
        "            total_loss_cb_sigmoid += loss_cb_sigmoid.item()\n",
        "\n",
        "          if train_cb_softmax:\n",
        "            loss_cb_softmax = cb_cel(\n",
        "                rn_cb_softmax(input),\n",
        "                target\n",
        "            ) / target.shape[0]\n",
        "            \n",
        "            loss_cb_softmax.backward()\n",
        "            total_loss_cb_softmax += loss_cb_softmax.item()\n",
        "\n",
        "          optimizer.step()\n",
        "\n",
        "          if print_training and \\\n",
        "            ((epoch == 0 and i == 0) or (i % print_freq == (print_freq - 1))):\n",
        "            print(\"Epoch:\", epoch, \"| Batch:\", str(i + 1))\n",
        "\n",
        "            if train_focal:\n",
        "              print(\"Focal:\".rjust(11), total_loss_focal/(i+1))\n",
        "            if train_sigmoid:\n",
        "              print(\"Sigmoid:\".rjust(11), total_loss_sigmoid/(i+1))\n",
        "            if train_softmax:\n",
        "              print(\"Softmax:\".rjust(11), total_loss_softmax/(i+1))\n",
        "            if train_cb_focal:\n",
        "              print(\"CB Focal:\".rjust(11), total_loss_cb_focal/(i+1))\n",
        "            if train_cb_sigmoid:\n",
        "              print(\"CB Sigmoid:\", total_loss_cb_sigmoid/(i+1))\n",
        "            if train_cb_softmax:\n",
        "              print(\"CB Softmax:\", total_loss_cb_softmax/(i+1))\n",
        "            \n",
        "            print()  # Print empty line\n",
        "        else:  # The end of each epoch\n",
        "          if save_models:  # Temporary backup for each epoch\n",
        "            # Delete all temporary files under temp/epoch_end/\n",
        "            for f in os.listdir(models_path + \"temp/epoch_end/\"):\n",
        "              fpath = models_path + \"temp/epoch_end/\" + f\n",
        "              os.remove(fpath)\n",
        "              #print(\"Removed:\", fpath)\n",
        "\n",
        "            if train_focal:\n",
        "              torch.save(\n",
        "                  rn_focal.state_dict(),\n",
        "                  models_path + f\"temp/epoch_end/rn{resnet_type}_focal_{dataset}_epoch{epoch}_batch{i+1}.pth\"\n",
        "              )\n",
        "              #print(f\"Saved model (ResNet-{resnet_type} focal, {DSET_NAMES[dataset]}):\",\n",
        "              #      models_path + f\"temp/epoch_end/rn{resnet_type}_focal_{dataset}_epoch{epoch}_batch{i+1}.pth\")\n",
        "\n",
        "            if train_sigmoid:\n",
        "              torch.save(\n",
        "                  rn_sigmoid.state_dict(),\n",
        "                  models_path + f\"temp/epoch_end/rn{resnet_type}_sigmoid_{dataset}_epoch{epoch}_batch{i+1}.pth\"\n",
        "              )\n",
        "              #print(f\"Saved model (ResNet-{resnet_type} sigmoid, {DSET_NAMES[dataset]}):\",\n",
        "              #      models_path + f\"temp/epoch_end/rn{resnet_type}_sigmoid_{dataset}_epoch{epoch}_batch{i+1}.pth\")\n",
        "\n",
        "            if train_softmax:\n",
        "              torch.save(\n",
        "                  rn_softmax.state_dict(),\n",
        "                  models_path + f\"temp/epoch_end/rn{resnet_type}_softmax_{dataset}_epoch{epoch}_batch{i+1}.pth\"\n",
        "              )\n",
        "              #print(f\"Saved model (ResNet-{resnet_type} softmax, {DSET_NAMES[dataset]}):\",\n",
        "              #      models_path + f\"temp/epoch_end/rn{resnet_type}_softmax_{dataset}_epoch{epoch}_batch{i+1}.pth\")\n",
        "            \n",
        "            if train_cb_focal:\n",
        "              torch.save(\n",
        "                  rn_cb_focal.state_dict(),\n",
        "                  models_path + f\"temp/epoch_end/rn{resnet_type}_cb_focal_{dataset}_epoch{epoch}_batch{i+1}.pth\"\n",
        "              )\n",
        "              #print(f\"Saved model (ResNet-{resnet_type} cb. focal, {DSET_NAMES[dataset]}):\",\n",
        "              #      models_path + f\"temp/epoch_end/rn{resnet_type}_cb_focal_{dataset}_epoch{epoch}_batch{i+1}.pth\")\n",
        "            \n",
        "            if train_cb_sigmoid:\n",
        "              torch.save(\n",
        "                  rn_cb_sigmoid.state_dict(),\n",
        "                  models_path + f\"temp/epoch_end/rn{resnet_type}_cb_sigmoid_{dataset}_epoch{epoch}_batch{i+1}.pth\"\n",
        "              )\n",
        "              #print(f\"Saved model (ResNet-{resnet_type} cb. sigmoid, {DSET_NAMES[dataset]}):\",\n",
        "              #      models_path + f\"temp/epoch_end/rn{resnet_type}_cb_sigmoid_{dataset}_epoch{epoch}_batch{i+1}.pth\")\n",
        "            \n",
        "            if train_cb_softmax:\n",
        "              torch.save(\n",
        "                  rn_cb_softmax.state_dict(),\n",
        "                  models_path + f\"temp/epoch_end/rn{resnet_type}_cb_softmax_{dataset}_epoch{epoch}_batch{i+1}.pth\"\n",
        "              )\n",
        "              #print(f\"Saved model (ResNet-{resnet_type} cb. softmax, {DSET_NAMES[dataset]}):\",\n",
        "              #      models_path + f\"temp/epoch_end/rn{resnet_type}_cb_softmax_{dataset}_epoch{epoch}_batch{i+1}.pth\")\n",
        "          \n",
        "          if draw_plots:\n",
        "            if train_focal:\n",
        "              history_loss_focal.append(total_loss_focal/(i+1))\n",
        "            if train_sigmoid:\n",
        "              history_loss_sigmoid.append(total_loss_sigmoid/(i+1))\n",
        "            if train_softmax:\n",
        "              history_loss_softmax.append(total_loss_softmax/(i+1))\n",
        "            if train_cb_focal:\n",
        "              history_loss_cb_focal.append(total_loss_cb_focal/(i+1))\n",
        "            if train_cb_sigmoid:\n",
        "              history_loss_cb_sigmoid.append(total_loss_cb_sigmoid/(i+1))\n",
        "            if train_cb_softmax:\n",
        "              history_loss_cb_softmax.append(total_loss_cb_softmax/(i+1))\n",
        "\n",
        "          if print_training:\n",
        "            print(\"Epoch:\", epoch, \"| Batch:\", str(i + 1))\n",
        "\n",
        "            if train_focal:\n",
        "              print(\"Focal:\".rjust(11), total_loss_focal/(i+1))\n",
        "            if train_sigmoid:\n",
        "              print(\"Sigmoid:\".rjust(11), total_loss_sigmoid/(i+1))\n",
        "            if train_softmax:\n",
        "              print(\"Softmax:\".rjust(11), total_loss_softmax/(i+1))\n",
        "            if train_cb_focal:\n",
        "              print(\"CB Focal:\".rjust(11), total_loss_cb_focal/(i+1))\n",
        "            if train_cb_sigmoid:\n",
        "              print(\"CB Sigmoid:\", total_loss_cb_sigmoid/(i+1))\n",
        "            if train_cb_softmax:\n",
        "              print(\"CB Softmax:\", total_loss_cb_softmax/(i+1))\n",
        "            \n",
        "            print()  # Print empty line\n",
        "    except KeyboardInterrupt:\n",
        "      print(\"Got KeyboardInterrupt.\")\n",
        "\n",
        "      if save_models:\n",
        "        print(\"Deleting previous backups.\")\n",
        "        # Delete all temporary files under temp/interrupted/\n",
        "        for f in os.listdir(models_path + \"temp/interrupted/\"):\n",
        "          fpath = models_path + \"temp/interrupted/\" + f\n",
        "          os.remove(fpath)\n",
        "          print(\"Removed:\", fpath)\n",
        "        \n",
        "        print(\"Backing up the models.\")\n",
        "\n",
        "        if train_focal:\n",
        "          torch.save(\n",
        "              rn_focal.state_dict(),\n",
        "              models_path + f\"temp/interrupted/rn{resnet_type}_focal_{dataset}_epoch{epoch}_batch{i+1}.pth\"\n",
        "          )\n",
        "          print(f\"Saved model (ResNet-{resnet_type} focal, {DSET_NAMES[dataset]}):\",\n",
        "                models_path + f\"temp/interrupted/rn{resnet_type}_focal_{dataset}_epoch{epoch}_batch{i+1}.pth\")\n",
        "\n",
        "        if train_sigmoid:\n",
        "          torch.save(\n",
        "              rn_sigmoid.state_dict(),\n",
        "              models_path + f\"temp/interrupted/rn{resnet_type}_sigmoid_{dataset}_epoch{epoch}_batch{i+1}.pth\"\n",
        "          )\n",
        "          print(f\"Saved model (ResNet-{resnet_type} sigmoid, {DSET_NAMES[dataset]}):\",\n",
        "                models_path + f\"temp/interrupted/rn{resnet_type}_sigmoid_{dataset}_epoch{epoch}_batch{i+1}.pth\")\n",
        "\n",
        "        if train_softmax:\n",
        "          torch.save(\n",
        "              rn_softmax.state_dict(),\n",
        "              models_path + f\"temp/interrupted/rn{resnet_type}_softmax_{dataset}_epoch{epoch}_batch{i+1}.pth\"\n",
        "          )\n",
        "          print(f\"Saved model (ResNet-{resnet_type} softmax, {DSET_NAMES[dataset]}):\",\n",
        "                models_path + f\"temp/interrupted/rn{resnet_type}_softmax_{dataset}_epoch{epoch}_batch{i+1}.pth\")\n",
        "        \n",
        "        if train_cb_focal:\n",
        "          torch.save(\n",
        "              rn_cb_focal.state_dict(),\n",
        "              models_path + f\"temp/interrupted/rn{resnet_type}_cb_focal_{dataset}_epoch{epoch}_batch{i+1}.pth\"\n",
        "          )\n",
        "          print(f\"Saved model (ResNet-{resnet_type} cb. focal, {DSET_NAMES[dataset]}):\",\n",
        "                models_path + f\"temp/interrupted/rn{resnet_type}_cb_focal_{dataset}_epoch{epoch}_batch{i+1}.pth\")\n",
        "        \n",
        "        if train_cb_sigmoid:\n",
        "          torch.save(\n",
        "              rn_cb_sigmoid.state_dict(),\n",
        "              models_path + f\"temp/interrupted/rn{resnet_type}_cb_sigmoid_{dataset}_epoch{epoch}_batch{i+1}.pth\"\n",
        "          )\n",
        "          print(f\"Saved model (ResNet-{resnet_type} cb. sigmoid, {DSET_NAMES[dataset]}):\",\n",
        "                models_path + f\"temp/interrupted/rn{resnet_type}_cb_sigmoid_{dataset}_epoch{epoch}_batch{i+1}.pth\")\n",
        "        \n",
        "        if train_cb_softmax:\n",
        "          torch.save(\n",
        "              rn_cb_softmax.state_dict(),\n",
        "              models_path + f\"temp/interrupted/rn{resnet_type}_cb_softmax_{dataset}_epoch{epoch}_batch{i+1}.pth\"\n",
        "          )\n",
        "          print(f\"Saved model (ResNet-{resnet_type} cb. softmax, {DSET_NAMES[dataset]}):\",\n",
        "                models_path + f\"temp/interrupted/rn{resnet_type}_cb_softmax_{dataset}_epoch{epoch}_batch{i+1}.pth\")\n",
        "      \n",
        "      print(\"Terminating.\")\n",
        "      sys.exit(1)\n",
        "    \n",
        "  \n",
        "    # Save the trained models\n",
        "\n",
        "    if save_models:\n",
        "      if train_focal:\n",
        "        torch.save(\n",
        "            rn_focal.state_dict(),\n",
        "            models_path + f\"rn{resnet_type}_focal_{dataset}.pth\"\n",
        "        )\n",
        "        print(f\"Saved model (ResNet-{resnet_type} focal, {DSET_NAMES[dataset]}):\",\n",
        "              models_path + f\"rn{resnet_type}_focal_{dataset}.pth\")\n",
        "\n",
        "      if train_sigmoid:\n",
        "        torch.save(\n",
        "            rn_sigmoid.state_dict(),\n",
        "            models_path + f\"rn{resnet_type}_sigmoid_{dataset}.pth\"\n",
        "        )\n",
        "        print(f\"Saved model (ResNet-{resnet_type} sigmoid, {DSET_NAMES[dataset]}):\",\n",
        "              models_path + f\"rn{resnet_type}_sigmoid_{dataset}.pth\")\n",
        "\n",
        "      if train_softmax:\n",
        "        torch.save(\n",
        "            rn_softmax.state_dict(),\n",
        "            models_path + f\"rn{resnet_type}_softmax_{dataset}.pth\"\n",
        "        )\n",
        "        print(f\"Saved model (ResNet-{resnet_type} softmax, {DSET_NAMES[dataset]}):\",\n",
        "              models_path + f\"rn{resnet_type}_softmax_{dataset}.pth\")\n",
        "      \n",
        "      if train_cb_focal:\n",
        "        torch.save(\n",
        "            rn_cb_focal.state_dict(),\n",
        "            models_path + f\"rn{resnet_type}_cb_focal_{dataset}.pth\"\n",
        "        )\n",
        "        print(f\"Saved model (ResNet-{resnet_type} cb. focal, {DSET_NAMES[dataset]}):\",\n",
        "              models_path + f\"rn{resnet_type}_cb_focal_{dataset}.pth\")\n",
        "      \n",
        "      if train_cb_sigmoid:\n",
        "        torch.save(\n",
        "            rn_cb_sigmoid.state_dict(),\n",
        "            models_path + f\"rn{resnet_type}_cb_sigmoid_{dataset}.pth\"\n",
        "        )\n",
        "        print(f\"Saved model (ResNet-{resnet_type} cb. sigmoid, {DSET_NAMES[dataset]}):\",\n",
        "              models_path + f\"rn{resnet_type}_cb_sigmoid_{dataset}.pth\")\n",
        "      \n",
        "      if train_cb_softmax:\n",
        "        torch.save(\n",
        "            rn_cb_softmax.state_dict(),\n",
        "            models_path + f\"rn{resnet_type}_cb_softmax_{dataset}.pth\"\n",
        "        )\n",
        "        print(f\"Saved model (ResNet-{resnet_type} cb. softmax, {DSET_NAMES[dataset]}):\",\n",
        "              models_path + f\"rn{resnet_type}_cb_softmax_{dataset}.pth\")\n",
        "    \n",
        "    if draw_plots:\n",
        "      legend = []\n",
        "      plt.figure(figsize=(16, 12))\n",
        "\n",
        "      if train_focal:\n",
        "        plt.plot(history_loss_focal, \"-b\")\n",
        "        legend.append(\"Focal Loss\")\n",
        "      if train_sigmoid:\n",
        "        plt.plot(history_loss_sigmoid, \"-r\")\n",
        "        legend.append(\"Sigmoid CE Loss\")\n",
        "      if train_softmax:\n",
        "        plt.plot(history_loss_softmax, \"-g\")\n",
        "        legend.append(\"CE Loss\")\n",
        "      if train_cb_focal:\n",
        "        plt.plot(history_loss_cb_focal, \"-c\")\n",
        "        legend.append(\"Class-Balanced Focal Loss\")\n",
        "      if train_cb_sigmoid:\n",
        "        plt.plot(history_loss_cb_sigmoid, \"-m\")\n",
        "        legend.append(\"Class-Balanced Sigmoid CE Loss\")\n",
        "      if train_cb_softmax:\n",
        "        plt.plot(history_loss_cb_softmax, \"-y\")\n",
        "        legend.append(\"Class-Balanced CE Loss\")\n",
        "      \n",
        "      if legend:\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend(legend)\n",
        "        plt.title(\n",
        "          f\"Loss vs. Epochs on {DSET_NAMES[dataset]} with ResNet-{resnet_type}\"\n",
        "        )\n",
        "\n",
        "        if not use_gdrive: \n",
        "          plt.savefig(\n",
        "            f\"./plots/{dataset.lower()}_rn-{resnet_type}-losses.png\"\n",
        "          )\n",
        "        \n",
        "        plt.show()\n",
        "  \n",
        "  return (rn_focal, rn_sigmoid, rn_softmax, rn_cb_focal, rn_cb_sigmoid,\n",
        "          rn_cb_softmax)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  models = train_models(train_dl, class_cnt, weights)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTJhjXMa6UdD"
      },
      "source": [
        "# Test the accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TFJIO1gcYFOk",
        "outputId": "284d513c-02f8-4200-d75c-b4a07c22eafa"
      },
      "source": [
        "def acc_results(models, test_dl, test_class_sizes, calc_avg=True, \n",
        "                calc_perclass=True, top=ACCURACY_TOP, dataset=DATASET,\n",
        "                resnet_type=RESNET_TYPE, draw_plots=DRAW_PLOTS,\n",
        "                use_gdrive=USE_GOOGLE_DRIVE, test_focal=TEST_FOCAL,\n",
        "                test_sigmoid=TEST_SIGMOID, test_softmax=TEST_SOFTMAX,\n",
        "                test_cb_focal=TEST_CB_FOCAL, test_cb_sigmoid=TEST_CB_SIGMOID,\n",
        "                test_cb_softmax=TEST_CB_SOFTMAX):\n",
        "  results = [None] * 6\n",
        "  \n",
        "  if not (calc_avg or calc_perclass): return results\n",
        "\n",
        "  if test_focal:\n",
        "    avg, pc = get_accuracy(test_dl, models[0].eval(), test_class_sizes, \n",
        "                           calc_avg=calc_avg, calc_perclass=calc_perclass, \n",
        "                           top=top)\n",
        "\n",
        "    results[0] = (avg, pc)\n",
        "\n",
        "    print(\"ResNet with unweighted focal loss:\")\n",
        "    if calc_avg: print(f\"    Average top-{top} accuracy:\", avg)\n",
        "    if calc_perclass: print(f\"  Top-{top} Accuracy per class:\", pc)\n",
        "\n",
        "    if draw_plots:\n",
        "      plt.figure(figsize=(16, 12))\n",
        "      plt.bar(np.arange(10), pc.tolist())\n",
        "      plt.xlabel(\"Class\")\n",
        "      plt.ylabel(\"Accuracy\")\n",
        "      plt.title(f\"Focal Loss Model Top-{top} Accuracy Per Class\")\n",
        "\n",
        "      if not use_gdrive:\n",
        "        plt.savefig(\n",
        "          f\"./plots/{dataset.lower()}_rn-{resnet_type}_focal_accuracy.png\"\n",
        "        )\n",
        "      \n",
        "      plt.show()\n",
        "      \n",
        "  if test_sigmoid:\n",
        "    avg, pc = get_accuracy(test_dl, models[1].eval(), test_class_sizes, \n",
        "                           calc_avg=calc_avg, calc_perclass=calc_perclass,\n",
        "                           top=top)\n",
        "\n",
        "    results[1] = (avg, pc)\n",
        "\n",
        "    print(\"ResNet with unweighted sigmoid loss:\")\n",
        "    if calc_avg: print(f\"    Average top-{top} accuracy:\", avg)\n",
        "    if calc_perclass: print(f\"  Top-{top} Accuracy per class:\", pc)\n",
        "\n",
        "    if draw_plots:\n",
        "      plt.figure(figsize=(16, 12))\n",
        "      plt.bar(np.arange(10), pc.tolist())\n",
        "      plt.xlabel(\"Class\")\n",
        "      plt.ylabel(\"Accuracy\")\n",
        "      plt.title(f\"Binary CE Loss (Sigmoid) Model Top-{top} Accuracy Per Class\")\n",
        "\n",
        "      if not use_gdrive: \n",
        "        plt.savefig(\n",
        "          f\"./plots/{dataset.lower()}_rn-{resnet_type}_sigmoid_accuracy.png\"\n",
        "        )\n",
        "      \n",
        "      plt.show()\n",
        "  \n",
        "  if test_softmax:\n",
        "    avg, pc = get_accuracy(test_dl, models[2].eval(), test_class_sizes,\n",
        "                           calc_avg=calc_avg, calc_perclass=calc_perclass, \n",
        "                           top=top)\n",
        "\n",
        "    results[2] = (avg, pc)\n",
        "\n",
        "    print(\"ResNet with unweighted softmax loss:\")\n",
        "    if calc_avg: print(f\"    Average top-{top} accuracy:\", avg)\n",
        "    if calc_perclass: print(f\"  Top-{top} Accuracy per class:\", pc)\n",
        "\n",
        "    if draw_plots:\n",
        "      plt.figure(figsize=(16, 12))\n",
        "      plt.bar(np.arange(10), pc.tolist())\n",
        "      plt.xlabel(\"Class\")\n",
        "      plt.ylabel(\"Accuracy\")\n",
        "      plt.title(f\"CE Loss (Softmax) Model Top-{top} Accuracy Per Class\")\n",
        "\n",
        "      if not use_gdrive: \n",
        "        plt.savefig(\n",
        "          f\"./plots/{dataset.lower()}_rn-{resnet_type}_softmax_accuracy.png\"\n",
        "        )\n",
        "      \n",
        "      plt.show()\n",
        "  \n",
        "  if test_cb_focal:\n",
        "    avg, pc = get_accuracy(test_dl, models[3].eval(), test_class_sizes, \n",
        "                           calc_avg=calc_avg, calc_perclass=calc_perclass, \n",
        "                           top=top)\n",
        "\n",
        "    results[3] = (avg, pc)\n",
        "\n",
        "    print(\"ResNet with class-balanced focal loss:\")\n",
        "    if calc_avg: print(f\"    Average top-{top} accuracy:\", avg)\n",
        "    if calc_perclass: print(f\"  Top-{top} Accuracy per class:\", pc)\n",
        "\n",
        "    if draw_plots:\n",
        "      plt.figure(figsize=(16, 12))\n",
        "      plt.bar(np.arange(10), pc.tolist())\n",
        "      plt.xlabel(\"Class\")\n",
        "      plt.ylabel(\"Accuracy\")\n",
        "      plt.title(f\"Weighted Focal Loss Model Top-{top} Accuracy Per Class\")\n",
        "\n",
        "      if not use_gdrive: \n",
        "        plt.savefig(\n",
        "          f\"./plots/{dataset.lower()}_rn-{resnet_type}_cb_focal_accuracy.png\"\n",
        "        )\n",
        "      \n",
        "      plt.show()\n",
        "  \n",
        "  if test_cb_sigmoid:\n",
        "    avg, pc = get_accuracy(test_dl, models[4].eval(), test_class_sizes, \n",
        "                           calc_avg=calc_avg, calc_perclass=calc_perclass, \n",
        "                           top=top)\n",
        "\n",
        "    results[4] = (avg, pc)\n",
        "\n",
        "    print(\"ResNet with class-balanced sigmoid loss:\")\n",
        "    if calc_avg: print(f\"    Average top-{top} accuracy:\", avg)\n",
        "    if calc_perclass: print(f\"  Top-{top} Accuracy per class:\", pc)\n",
        "\n",
        "    if draw_plots:\n",
        "      plt.figure(figsize=(16, 12))\n",
        "      plt.bar(np.arange(10), pc.tolist())\n",
        "      plt.xlabel(\"Class\")\n",
        "      plt.ylabel(\"Accuracy\")\n",
        "      plt.title(f\"Weighted Binary CE Loss (Sigmoid) Model Top-{top} Accuracy Per Class\")\n",
        "\n",
        "      if not use_gdrive: \n",
        "        plt.savefig(\n",
        "          f\"./plots/{dataset.lower()}_rn-{resnet_type}_cb_sigmoid_accuracy.png\"\n",
        "        )\n",
        "      \n",
        "      plt.show()\n",
        "  \n",
        "  if test_cb_softmax:\n",
        "    avg, pc = get_accuracy(test_dl, models[5].eval(), test_class_sizes,\n",
        "                           calc_avg=calc_avg, calc_perclass=calc_perclass,\n",
        "                           top=top)\n",
        "\n",
        "    results[5] = (avg, pc)\n",
        "\n",
        "    print(\"ResNet with class-balanced softmax loss:\")\n",
        "    if calc_avg: print(f\"    Average top-{top} accuracy:\", avg)\n",
        "    if calc_perclass: print(f\"  Top-{top} Accuracy per class:\", pc)\n",
        "\n",
        "    if draw_plots:\n",
        "      plt.figure(figsize=(16, 12))\n",
        "      plt.bar(np.arange(10), pc)\n",
        "      plt.xlabel(\"Class\")\n",
        "      plt.ylabel(\"Accuracy\")\n",
        "      plt.title(f\"Weighted CE Loss (Softmax) Model Top-{top} Accuracy Per Class\")\n",
        "\n",
        "      if not use_gdrive: \n",
        "        plt.savefig(\n",
        "          f\"./plots/{dataset.lower()}_rn-{resnet_type}_cb_softmax_accuracy.png\"\n",
        "        )\n",
        "      \n",
        "      plt.show()\n",
        "\n",
        "  return results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  acc_results(models, test_dl, test_class_sizes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet with unweighted focal loss:\n",
            "    Average top-1 accuracy: tensor(0.4478)\n",
            "  Top-1 Accuracy per class: tensor([0.9910, 0.9450, 0.7180, 0.5150, 0.5200, 0.3170, 0.2710, 0.1370, 0.0520,\n",
            "        0.0120])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "ResNet with unweighted sigmoid loss:\n",
            "    Average top-1 accuracy: tensor(0.4537)\n",
            "  Top-1 Accuracy per class: tensor([0.9920, 0.9520, 0.7180, 0.5160, 0.5520, 0.3080, 0.2760, 0.1640, 0.0470,\n",
            "        0.0120])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "ResNet with unweighted softmax loss:\n",
            "    Average top-1 accuracy: tensor(0.4670)\n",
            "  Top-1 Accuracy per class: tensor([0.9840, 0.9410, 0.7270, 0.5350, 0.5530, 0.3250, 0.3290, 0.1880, 0.0600,\n",
            "        0.0280])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "ResNet with class-balanced focal loss:\n",
            "    Average top-1 accuracy: tensor(0.5037)\n",
            "  Top-1 Accuracy per class: tensor([0.8830, 0.8670, 0.5040, 0.3670, 0.4630, 0.3540, 0.4930, 0.3840, 0.3670,\n",
            "        0.3550])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "ResNet with class-balanced sigmoid loss:\n",
            "    Average top-1 accuracy: tensor(0.4715)\n",
            "  Top-1 Accuracy per class: tensor([0.8660, 0.8240, 0.4670, 0.2990, 0.4530, 0.3110, 0.4590, 0.3180, 0.3660,\n",
            "        0.3520])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "ResNet with class-balanced softmax loss:\n",
            "    Average top-1 accuracy: tensor(0.4703)\n",
            "  Top-1 Accuracy per class: tensor([0.8480, 0.8280, 0.4670, 0.3690, 0.4890, 0.2700, 0.4980, 0.3640, 0.3740,\n",
            "        0.1960])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}